---
title: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, error=F, warning=F)
library(tidyverse) # CSV file I/O, e.g. the read_csv function
library(RColorBrewer)
library(viridis)
#plotly
library(plotly) #contain hex to RGB conversion
# set plotly user name
#Sys.setenv("plotly_username"="HanYan")
# set plotly API key
#Sys.setenv("plotly_api_key"="BMtBFRWCdY4ni069FJsx")

#date
library(lubridate)
#special
library(packcircles)
#text
library(tidytext)
library(quanteda)
#library(udpipe)
#animate
#library(gganimate)
#theme
my_theme <- function(base_size = 12, base_family = "Helvetica"){
    theme_minimal() +
    theme(axis.title.y = element_blank(),axis.title.x = element_blank(),
    plot.title = element_text(face="bold", size=16),
    axis.text = element_text(face="bold"),
    plot.background = element_rect(fill = 'ghostwhite',color='white'),
    legend.position = 'None', legend.title = element_blank())
}

```

#Section 1: input
## Load a bath of files
```{r}
setwd("/Users/hannah/git_repo/opendata_viz/lyric_repetitiveness")
temp <- list.files(pattern="*.txt")
file <- do.call(rbind,lapply(temp,readLines))
df_song <- data.frame(line = c(1:length(file[1, ]),
                               1:length(file[2, ]),
                               1:length(file[3, ])),
                      txt = c(file[1, ], file[2, ], file[3, ]),
                      song = c(
                        rep("Havana", length(file[1, ])),
                        rep("Hello", length(file[1, ])),
                        rep("Shape of you", length(file[1, ]))
                      ))
```



```{r input}
df = df_song %>% 
  mutate(txt = as.character(txt), song = as.character(song)) %>%
#remove bracket
  mutate(txt_original = as.character(tolower(txt)),
         txt=str_replace_all(txt_original, '\\(.*?\\)', ''))
```

# Section 2: Text processing

```{r}
# use this to zoom into a potential pool of phrases
# topfeatures(dfm(df$txt, ngrams = c(2,8), verbose = FALSE), n=30)
```

step 1: identify common repetitive phrases with the aid of quanteda
```{r}
phrase = c(
  "my heart is in havana",
  "ooh.na-na",
  "oh na-na-na",
  "took me back to east atlanta",
  "take me back",
  "hello from the other side",
  "i\'m sorry for everything that i\'ve done",
  "i\'m sorry for breaking your heart",
  "i must have called a thousand times",
  "but when i call you never seem to be home",
  "at least i can say that i've tried",
  "i\'m in love with your body",
  "every day discovering something brand new",
  "come on now",
  "i\'m in love with the shape of you",
  "although my heart is falling too",
  "be my baby")
```

step 2: replace the phrases with dummy so one can still retrieve their locations, then tokenize the rest
```{r}
replacement = paste0("dummy",1:length(phrase))

patternreplace = function(x, patterns, replacements = patterns, fill = NA, ...)
{
  stopifnot(length(patterns) == length(replacements))
  ans = x  
  empty = seq_along(x)
  
  for(i in seq_along(patterns)) {
    greps = grepl(patterns[[i]], x[empty], ... , ignore.case = T)
    ans[empty[greps]] = replacements[[i]]  
    empty = empty[!greps]
  }
  return(ans)
}
```

use 1 word to replace the phrase then dup it back, pattern replace and reverse pattern replace to incorporate custom token

```{r token}
custom_token <- function(df, phrase, replacement) {
  df_word <- df %>% 
    mutate(txt = patternreplace(txt, phrase, replacement))%>%
    unnest_tokens(word, txt) %>% 
    mutate(word = patternreplace(word, replacement, phrase))%>%
    group_by(song) %>%
    mutate(id=1:n()) %>%
    ungroup()
  return(df_word)
}

```

```{r}
df_word <- custom_token(df, phrase, replacement)

df_half <- df_word %>%
  group_by(song) %>%
  filter(line<round(max(line)/2))%>%
  ungroup() %>%
  group_by(word, song) %>%
  summarize(n = n(), id = min(id))

df_combined <- df_word %>%
    group_by(word, song) %>%
    summarize(n = n(), id = min(id))
```


# Section 3: Visualization
## calc circle packing layout, return a list of dataframe
```{r fun}
circle_layout <- function(df, n) {
  packing <- circleProgressiveLayout(df$n, sizetype='area')
  #leave gaps between circles
  packing$radius=0.8*packing$radius
  
  #data contains coordinate/radius of each circle
  data = cbind(data.frame(df), packing) 
  #dat.gg layout each vertice on the polygon which is a proxy for circle
  dat.gg <- circleLayoutVertices(packing, npoints=50)
  # out <- list()
  # out$packing = packing
  # out$data = data
  # out$dat.gg = dat.gg
  # return(out)
  # these are for checking by step
  circles = dat.gg %>% 
    left_join(data[c("id","word","n","song")], by = "id")
  return(circles)
}
```


```{r}
show_digest <- function(df_combined, df_half) {
  df_dummy <- df_combined %>% 
  mutate(n = 1)
  
  x <- circle_layout(df_dummy, n) %>% 
  mutate(state = as.factor("if no repetition"))
  k <- circle_layout(df_half, n) %>% 
  mutate(state = as.factor("half way into the song"))
  y <- circle_layout(df_combined, n) %>% 
  mutate(state = as.factor("full song"))

  z <- x %>%
    rbind(k) %>%
    rbind(y)
  
  return(z)
}
```


```{r}
i="Havana"
png(paste0(i, ".png"), width=600, height=360)
show_digest(
  subset(df_combined, song==i), 
  subset(df_half, song==i)) %>%
  ggplot() + 
  geom_polygon(aes(x, y, fill = id, group = id),   alpha = 0.8) +
  scale_fill_viridis(option="plasma", direction = -1, 
                     begin = 0.05, end=0.7) +
  #geom_text(aes(x, y, size=value, label = group), color="black") +
  theme_void() + 
  theme(legend.position="none",
        text=element_text(size=14))+ 
  coord_equal() + 
  facet_grid(.~state) 
dev.off()


```

